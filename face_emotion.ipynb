{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807f721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e660d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c2f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b481f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir=r\"D:\\project file\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bce8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_dir=r\"D:\\project file\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b8ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=30,shear_range=0.3,zoom_range=0.3,horizontal_flip=True,fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c72f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64b3433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(train_data_dir,color_mode='grayscale',target_size=(48,48),batch_size=32,class_mode='categorical',shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413a4c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=validation_datagen.flow_from_directory(validation_data_dir,color_mode='grayscale',target_size=(48,48),batch_size=32,class_mode='categorical',shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b782a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_lables=['Angry','Disgust','Fear','Happy','Neutral','Sad','Suprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f747eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label = train_generator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6336072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb141c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(48,48,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e7dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1508e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "927ec5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(256,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ad3ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ba7103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(512,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c8dde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67683582",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(7,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0adf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93d06486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 44, 44, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 22, 22, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,489,095\n",
      "Trainable params: 2,489,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f506b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=r\"D:\\project file\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a451b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path=r\"D:\\project file\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41b6f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_imgs=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "272e278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(train_path):\n",
    "    num_train_imgs +=len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d05a0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_imgs=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcc3fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(train_path):\n",
    "    num_test_imgs +=len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a62b0829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n"
     ]
    }
   ],
   "source": [
    "print(num_train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "badba066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n"
     ]
    }
   ],
   "source": [
    "print(num_test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46430b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04c062d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "898/898 [==============================] - ETA: 0s - loss: 1.7741 - accuracy: 0.2664WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 897 batches). You may need to use the repeat() function when building your dataset.\n",
      "898/898 [==============================] - 226s 252ms/step - loss: 1.7741 - accuracy: 0.2664 - val_loss: 1.6873 - val_accuracy: 0.3378\n",
      "Epoch 2/2\n",
      "898/898 [==============================] - 210s 234ms/step - loss: 1.6578 - accuracy: 0.3378\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_generator,epochs=epochs,validation_data=validation_generator,validation_steps=num_test_imgs//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e1e3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modek_file.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c4e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
